{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0c096dc6f1a468aa3850648f98b3ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0b57a828f0549b7b79337b76e80dce7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6d0bff4b8d34fe59574074b0ecee234",
              "IPY_MODEL_a546756a93e940058d83ad78b923feea"
            ]
          }
        },
        "c0b57a828f0549b7b79337b76e80dce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6d0bff4b8d34fe59574074b0ecee234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4afe5669d1c6431bb84e545b74380407",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a36b0b3c1b4455aa7151087bd44fc9e"
          }
        },
        "a546756a93e940058d83ad78b923feea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9133689867c848418ad46545555772be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [08:11&lt;00:00, 209kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d15c6b454e104a4485237905b77c6f11"
          }
        },
        "4afe5669d1c6431bb84e545b74380407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a36b0b3c1b4455aa7151087bd44fc9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9133689867c848418ad46545555772be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d15c6b454e104a4485237905b77c6f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfykHkgYejP9",
        "outputId": "be2bf247-ee7d-4cac-d5d8-86021b3c536d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBfV9gZN8V3f",
        "outputId": "033d0a1d-ac07-417b-e3e9-7ffb8b4273f5"
      },
      "source": [
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 8.5MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTCI-JE88nvX",
        "outputId": "2ee20b22-57ad-4f72-9e8d-763e891a54ba"
      },
      "source": [
        "!pip install transformers==3.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 16.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2020.12.5)\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.10.2\n",
            "    Uninstalling tokenizers-0.10.2:\n",
            "      Successfully uninstalled tokenizers-0.10.2\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-vZtZvgfbMn"
      },
      "source": [
        "import sklearn\n",
        "import time\n",
        "import datetime,math,os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import lightgbm as lgb\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import traceback\n",
        "from torchvision import transforms as T\n",
        "\n",
        "MODE = 'TEST' # DEV/TEST\n",
        "ISPREDICT = False  \n",
        "weight_path = '/content/drive/MyDrive/hateful-memes/weight'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3XNmZVvgM7m",
        "outputId": "9294666f-8c59-4b69-e8b8-5bb97c469d76"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/hateful-memes/csv/train.csv')\n",
        "train2 = pd.read_csv('/content/drive/MyDrive/hateful-memes/csv/dev1.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/hateful-memes/csv/test1.csv')\n",
        "train3 = pd.read_csv('/content/drive/MyDrive/hateful-memes/csv/dev2.csv')\n",
        "test2 = pd.read_csv('/content/drive/MyDrive/hateful-memes/csv/test2.csv')\n",
        "train2 = train3.append(train2).drop_duplicates('id',keep='first')\n",
        "train.shape,train2.shape,test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8500, 8), (30, 8), (30, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9bPn4Txhv7I"
      },
      "source": [
        "def findId(id):\n",
        "    if id in train.id.tolist():\n",
        "        return \"train\"\n",
        "    if id in train2.id.tolist():\n",
        "        return \"train2\"\n",
        "    if id in train3.id.tolist():\n",
        "        return \"train3\"\n",
        "    if id in test.id.tolist():\n",
        "        return \"test\"\n",
        "    if id in test2.id.tolist():\n",
        "        return \"test2\"\n",
        "    return 'unk'\n",
        "\n",
        "same_id_dict = {}\n",
        "for line in open('/content/drive/MyDrive/hateful-memes/hate/hateful/model/same_id.csv','r'):\n",
        "    if line == '':\n",
        "        continue\n",
        "    array = line.strip().split(' ')\n",
        "    same_id_dict[int(array[1])] = int(array[0])\n",
        "\n",
        "for id,v in same_id_dict.items():\n",
        "    temp_id = id\n",
        "    while(True):\n",
        "        if same_id_dict.get(temp_id, -1) != -1:\n",
        "            temp_id = same_id_dict[temp_id]\n",
        "            \n",
        "        else:\n",
        "            break\n",
        "    same_id_dict[id] = temp_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9MSjzAVgZOG"
      },
      "source": [
        "coco_dev = pd.read_csv('/content/drive/MyDrive/hateful-memes/hate/hateful/mmf/coco_output2.csv')\n",
        "id_mmf = {}\n",
        "cache = coco_dev[['id','proba']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_mmf[cache[i,0]] = cache[i,1]\n",
        "    \n",
        "coco_dev = pd.read_csv('/content/drive/MyDrive/hateful-memes/hate/hateful/mmf/coco_output.csv')\n",
        "cache = coco_dev[['id','proba']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_mmf[cache[i,0]] = cache[i,1]\n",
        "\n",
        "coco_dev = pd.read_csv('/content/drive/MyDrive/hateful-memes/hate/hateful/mmf/coco_sub.csv')\n",
        "cache = coco_dev[['id','proba']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_mmf[cache[i,0]] = cache[i,1]\n",
        "    \n",
        "coco_dev = pd.read_csv('/content/drive/MyDrive/hateful-memes/hate/hateful/mmf/coco_sub2.csv')\n",
        "cache = coco_dev[['id','proba']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_mmf[cache[i,0]] = cache[i,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PFq8H4zicVX"
      },
      "source": [
        "id_feat = {}\n",
        "id_weight_nltk = {}\n",
        "cache = train[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_feat[cache[i,0]]  = cache[i,2:]\n",
        "    if cache[i,1] == 1:\n",
        "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,4] - cache[i,2],0,0.5)\n",
        "    else:\n",
        "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,2] - cache[i,4],0,0.5)\n",
        "\n",
        "cache = train2[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_feat[cache[i,0]]  = cache[i,2:]\n",
        "    if cache[i,1] == 1:\n",
        "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,4] - cache[i,2],0,0.5)\n",
        "    else:\n",
        "        id_weight_nltk[cache[i,0]] = 1 - np.clip(cache[i,2] - cache[i,4],0,0.5)\n",
        "\n",
        "        \n",
        "cache = test[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_feat[cache[i,0]]  = cache[i,2:]\n",
        "    \n",
        "cache = test2[['id','label','nltk1','nltk2','nltk3','nltk4']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_feat[cache[i,0]]  = cache[i,2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNkBMA6Rignf"
      },
      "source": [
        "from tqdm import tqdm, tqdm_notebook\n",
        "img_size = 128\n",
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
        "    ratio = float(img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # new_size should be in (width, height) format\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = img_size - new_size[1]\n",
        "    delta_h = img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "def load_image(path, name):\n",
        "    image = (Image.open(path + name))\n",
        "    \n",
        "    transform1 = T.Compose([\n",
        "        T.Scale(img_size),\n",
        "        T.CenterCrop((img_size, img_size)),\n",
        "    ])\n",
        "    new_image = transform1(image)\n",
        "    new_image = np.array(new_image)\n",
        "    if len(new_image.shape) == 2:\n",
        "        new_image = np.repeat(new_image.reshape(img_size,img_size,1),3,axis = 2)\n",
        "    \n",
        "    if new_image.shape[2] > 3:\n",
        "        new_image = new_image[:,:,:3]\n",
        "    return new_image/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEkY34I6ilcn",
        "outputId": "23eb010c-cf9a-44fa-fcc6-bb3d371d3139"
      },
      "source": [
        "\n",
        "pic_cache = {}\n",
        "id_pic = {}\n",
        "id_text = {}\n",
        "id_label = {}\n",
        "cache = train[['id','img','label','text']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_pic[cache[i,0]]  = cache[i,1]\n",
        "    id_label[cache[i,0]] = cache[i,2]\n",
        "    pic_cache[cache[i,0]] = load_image(\"/content/drive/MyDrive/hateful-memes/\", cache[i,1])\n",
        "    id_text[cache[i,0]]  = cache[i,3]\n",
        "\n",
        "\n",
        "id_label2 = {}\n",
        "id_label3 = {}\n",
        "cache = train2[['id','img','label','text']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_pic[cache[i,0]]  = cache[i,1]\n",
        "    if MODE == 'TEST':\n",
        "        id_label[cache[i,0]] = cache[i,2]\n",
        "    else:\n",
        "        id_label2[cache[i,0]] = cache[i,2]\n",
        "    pic_cache[cache[i,0]] = load_image(\"/content/drive/MyDrive/hateful-memes/\", cache[i,1])\n",
        "    id_text[cache[i,0]]  = cache[i,3]\n",
        "\n",
        "ids_list = list(id_label.keys()) \n",
        "\n",
        "cache = test[['id','img','label','text']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_pic[cache[i,0]]  = cache[i,1]\n",
        "    pic_cache[cache[i,0]] = load_image(\"/content/drive/MyDrive/hateful-memes/\", cache[i,1])\n",
        "    id_text[cache[i,0]]  = cache[i,3]\n",
        "    \n",
        "cache = test2[['id','img','label','text']].values\n",
        "for i in range(cache.shape[0]):\n",
        "    id_pic[cache[i,0]]  = cache[i,1]\n",
        "    pic_cache[cache[i,0]] = load_image(\"/content/drive/MyDrive/hateful-memes/\", cache[i,1])\n",
        "    id_text[cache[i,0]]  = cache[i,3]\n",
        "    if MODE == 'TEST':\n",
        "        id_label2[cache[i,0]] = random.choice([0,1])\n",
        "ids_list2 = list(id_label2.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:285: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjJkOqlvuotr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import logging\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                        level = logging.INFO)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tokenizers\n",
        "from transformers import RobertaModel, RobertaConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
        "            vocab_file ='/content/drive/MyDrive/hateful-memes/hate/hateful/roberta-base-vocab.json', \n",
        "            merges_file ='/content/drive/MyDrive/hateful-memes/hate/hateful/roberta-base-merges.txt', \n",
        "            lowercase=True,\n",
        "            add_prefix_space=True)\n",
        "\n",
        "max_seq_length = 96\n",
        "\n",
        "def get_input_data(text):\n",
        "    text = \" \" + \" \".join(text.lower().split())\n",
        "    encoding = tokenizer.encode(text)\n",
        "    ids = [0] + encoding.ids + [2]\n",
        "    offsets = [(0, 0)] * 4 + encoding.offsets + [(0, 0)]\n",
        "                \n",
        "    pad_len = max_seq_length - len(ids)\n",
        "    if pad_len > 0:\n",
        "        ids += [1] * pad_len\n",
        "        offsets += [(0, 0)] * pad_len\n",
        "    elif pad_len < 0:\n",
        "        ids = ids[:max_seq_length]\n",
        "        offsets = offsets[:max_seq_length]\n",
        "    ids = torch.tensor(ids)\n",
        "    masks = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n",
        "        \n",
        "    return ids, masks\n",
        "\n",
        "class DensNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        preloaded = torchvision.models.resnet50(pretrained=True)\n",
        "        hidden1_size = 64\n",
        "        self.features = preloaded\n",
        "        self.features.conv1 = nn.Conv2d(3, 64, 7, 2, 3)\n",
        "        self.fci = nn.Linear(1000, hidden1_size, bias=True)\n",
        "        self.fct = nn.Linear(768 + 4, hidden1_size, bias=True)\n",
        "        self.fc2 = nn.Linear(hidden1_size * 3, 1, bias=True)\n",
        "#         del preloaded\n",
        "        \n",
        "        self.fc3 = nn.Linear(hidden1_size * 4, 32, bias=True)\n",
        "        self.fc4 = nn.Linear(32, 2, bias=True)\n",
        "        \n",
        "        config = RobertaConfig.from_pretrained(\n",
        "            '/content/drive/MyDrive/hateful-memes/hate/hateful/roberta-base-config.json', output_hidden_states=True)    \n",
        "        self.roberta = RobertaModel.from_pretrained(\n",
        "            '/content/drive/MyDrive/hateful-memes/hate/hateful/roberta-base-pytorch_model.bin', config=config)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fctext = nn.Linear(config.hidden_size, 16)\n",
        "        nn.init.normal_(self.fctext.weight, std=0.02)\n",
        "        nn.init.normal_(self.fctext.bias, 0)\n",
        "        \n",
        "        hidden_dim = 64\n",
        "        self.gate = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.tabular_dense = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.text_dense = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.bn_gate = nn.BatchNorm1d(hidden_dim)\n",
        "        \n",
        "    def middle(self, x):\n",
        "        features = self.features(x[0])\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = self.dropout(out)\n",
        "        out = (self.fci(out))\n",
        "        \n",
        "        hs1, hs0, hs = self.roberta(x[1], x[2])\n",
        "        hs0 = torch.cat([hs0,x[3]],1)\n",
        "        hs0 = self.dropout(hs0)\n",
        "        hs0 = (self.fct(hs0))\n",
        "        return [out,hs0]       \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out,hs0 = self.middle(x)\n",
        "        out = (torch.cat([out - hs0,hs0 * out, hs0], 1))\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "    def forward2(self, x):\n",
        "        out,hs0 = self.middle(x)\n",
        "        out1 = (torch.cat([out - hs0,hs0 * out, hs0], 1))\n",
        "        out1 = self.dropout(out1)\n",
        "        out1 = self.fc2(out1)\n",
        "        \n",
        "        out2 = (torch.cat([out * 0.0 - hs0,hs0 * out * 0.0, hs0], 1))\n",
        "        out2 = self.dropout(out2)\n",
        "        out2 = self.fc2(out2)\n",
        "\n",
        "        out3 = (torch.cat([out - hs0 * 0.0,hs0 * out * 0.0, hs0 * 0.0], 1))\n",
        "        out3 = self.dropout(out3)\n",
        "        out3 = self.fc2(out3)\n",
        "        return torch.cat([out1,out2,out3],1)\n",
        "\n",
        "    \n",
        "    def pair_forward(self, x1, x2):\n",
        "        result = []\n",
        "        for x in [x1,x2]:\n",
        "            out,hs0 = self.middle(x)\n",
        "            result.append(torch.cat([out,hs0],1))\n",
        "            \n",
        "        out = (self.fc3(torch.cat([result[0] - result[1],result[0] * result[1]], 1)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc4(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRIrqaTpynWw",
        "outputId": "ea6b8296-5a56-4231-e469-395b2241978a"
      },
      "source": [
        "img_pairs = []\n",
        "text_pairs = []\n",
        "for line in open('/content/drive/MyDrive/hateful-memes/hate/hateful/model/img_pairs.csv','r'):\n",
        "    if line == '':\n",
        "        continue\n",
        "    array = line.strip().split(' ')\n",
        "    img_pairs.append([int(array[0]),int(array[1])])\n",
        "    \n",
        "for line in open('/content/drive/MyDrive/hateful-memes/hate/hateful/model/text_pairs.csv','r'):\n",
        "    if line == '':\n",
        "        continue\n",
        "    array = line.strip().split(' ')\n",
        "    text_pairs.append([int(array[0]),int(array[1])])\n",
        "\n",
        "ids_list3 = [x for x in ids_list2]\n",
        "print(len(img_pairs),len(text_pairs),len(ids_list3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2711 3707 640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qaa8jKdfY4a0"
      },
      "source": [
        "id_pair = []\n",
        "id_sample_weight = {}\n",
        "for pairs in [text_pairs,img_pairs]:\n",
        "    id2cluster = {}\n",
        "    cluster2id = {}\n",
        "    clusterid = 0 \n",
        "    for line in pairs:\n",
        "        id0 = line[0]\n",
        "        id1 = line[1]\n",
        "        if id_label.get(id0,-1) == -1 and id_label2.get(id0,-1) == -1:\n",
        "            continue\n",
        "        if id_label.get(id1,-1) == -1 and id_label2.get(id1,-1) == -1:\n",
        "            continue\n",
        "        if id_label2.get(id0,-1) != -1 or id_label2.get(id1,-1) != -1:\n",
        "            if same_id_dict.get(id0,id0) != same_id_dict.get(id1,id1):\n",
        "                id_pair.append(line)\n",
        "    \n",
        "        if id2cluster.get(id0,-1) == -1 and id2cluster.get(id1,-1) == -1:\n",
        "            cluster2id[clusterid] = set()\n",
        "            cluster2id[clusterid].add(id0)\n",
        "            cluster2id[clusterid].add(id1)\n",
        "            id2cluster[id0] = clusterid\n",
        "            id2cluster[id1] = clusterid\n",
        "            clusterid += 1\n",
        "        elif id2cluster.get(id0,-1) != -1 or id2cluster.get(id1,-1) != -1:\n",
        "            if id2cluster.get(id0,-1) != -1:\n",
        "                clusterid_temp = id2cluster[id0]\n",
        "                cluster2id[clusterid_temp].add(id1)\n",
        "                id2cluster[id1] = clusterid_temp\n",
        "            if id2cluster.get(id1,-1) != -1:\n",
        "                clusterid_temp = id2cluster[id1]\n",
        "                cluster2id[clusterid_temp].add(id0)\n",
        "                id2cluster[id0] = clusterid_temp\n",
        "\n",
        "    clusterinfo = {}\n",
        "    valid_y = []\n",
        "    pred_y = []\n",
        "    for k,v in cluster2id.items():\n",
        "        l = list(v)\n",
        "        info = [0,0,0]\n",
        "        for id in l:\n",
        "            if id_label.get(id,-1) == -1:\n",
        "                info[2] +=1\n",
        "            if id_label.get(id,-1) != -1:\n",
        "                info[id_label.get(id,-1)] += 1\n",
        "\n",
        "                \n",
        "        distinct_id = set()\n",
        "        for id in l:\n",
        "            temp_id = id\n",
        "            while(True):\n",
        "                if same_id_dict.get(temp_id, -1) != -1:\n",
        "                    temp_id = same_id_dict[temp_id]\n",
        "                else:\n",
        "                    break\n",
        "            distinct_id.add(temp_id)\n",
        "        \n",
        "        for id in l:\n",
        "            id_sample_weight[id] = 1/len(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593,
          "referenced_widgets": [
            "e0c096dc6f1a468aa3850648f98b3ffb",
            "c0b57a828f0549b7b79337b76e80dce7",
            "f6d0bff4b8d34fe59574074b0ecee234",
            "a546756a93e940058d83ad78b923feea",
            "4afe5669d1c6431bb84e545b74380407",
            "5a36b0b3c1b4455aa7151087bd44fc9e",
            "9133689867c848418ad46545555772be",
            "d15c6b454e104a4485237905b77c6f11"
          ]
        },
        "id": "pb9su-Bn_-gC",
        "outputId": "86b32633-7027-4cb2-b216-be872fd2c14c"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion2 = nn.BCEWithLogitsLoss(reduction = 'none')\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "pair_batch_size = 8\n",
        "valid_batch_num = 16\n",
        "ep_num = 100\n",
        "n_batches = len(ids_list)//batch_size + 1\n",
        "valid_batch_num = len(ids_list3)//batch_size + 1\n",
        "\n",
        "\n",
        "id_pred_mid_all = []\n",
        "id_pred_all = []\n",
        "for fold in range(3):\n",
        "    model = DensNet()\n",
        "    model.to('cuda')\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9, 0.999))\n",
        "    if ISPREDICT:\n",
        "        model.load_state_dict(torch.load('/content/drive/MyDrive/hateful-memes/weight' + '/model3_' + str(fold) + '.pt'))\n",
        "    else:\n",
        "        for ep in range(5):\n",
        "            print('ep',ep)\n",
        "            random.shuffle(ids_list)\n",
        "            random.shuffle(img_pairs)\n",
        "            random.shuffle(text_pairs)\n",
        "            model.train()\n",
        "            tloss = 0.0\n",
        "            for b in range(n_batches):\n",
        "                start = b*batch_size\n",
        "                end = (b+1)*batch_size\n",
        "                batch_ids = ids_list[start:end]\n",
        "                batch_images = []\n",
        "                batch_feat = []\n",
        "                batch_text = []\n",
        "                batch_text2 = []\n",
        "                sample_weight = []\n",
        "                y = []\n",
        "                for i,id in enumerate(batch_ids):\n",
        "                    if len(batch_ids) == 0:\n",
        "                        continue\n",
        "                    try:\n",
        "                        batch_images.append(pic_cache[id])\n",
        "                        batch_feat.append(id_feat[id])\n",
        "                        y.append([id_label[id],id_label[id],id_label[id]])\n",
        "                        sample_weight.append([(max(id_sample_weight.get(id,1),0.2)) * 0.7 + id_weight_nltk.get(id,1) * 0.3])\n",
        "                        text_feat = get_input_data(id_text[id])\n",
        "                        batch_text.append(text_feat[0])\n",
        "                        batch_text2.append(text_feat[1])\n",
        "                    except:\n",
        "                        print(id,str(traceback.format_exc()))\n",
        "\n",
        "        #         print(';2',b)\n",
        "                y = torch.FloatTensor(y).to('cuda')\n",
        "                batch_feat = torch.FloatTensor(batch_feat).to('cuda')\n",
        "                batch_images = torch.FloatTensor(batch_images).to('cuda')\n",
        "                batch_text = torch.stack(batch_text, 0).to('cuda')\n",
        "                batch_text2 = torch.stack(batch_text2, 0).to('cuda')\n",
        "                sample_weight = torch.FloatTensor(sample_weight).to('cuda')\n",
        "                output = model.forward2([batch_images.permute(0,3,1,2),batch_text,batch_text2,batch_feat])\n",
        "                loss = (criterion2((output), y) * sample_weight).mean()\n",
        "                loss.backward()\n",
        "                if b % 2 == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "                tloss += loss.item() \n",
        "\n",
        "            print(\"loss:\",tloss/len(ids_list))\n",
        "            \n",
        "    if True:\n",
        "        model.eval()\n",
        "        id_pred_mid = {}\n",
        "        id_pred = {}\n",
        "        for b in range(valid_batch_num):\n",
        "            start = b*batch_size\n",
        "            end = (b+1)*batch_size\n",
        "            if start >= len(ids_list3):\n",
        "                continue\n",
        "            batch_ids = ids_list3[start:end]\n",
        "            batch_images = []\n",
        "            batch_feat = []\n",
        "            batch_text = []\n",
        "            batch_text2 = []\n",
        "            y = []\n",
        "            for i,id in enumerate(batch_ids):\n",
        "                if len(batch_ids) == 0:\n",
        "                    continue\n",
        "                try:\n",
        "                    batch_images.append(pic_cache[id])\n",
        "                    y.append(id_label2[id])\n",
        "                    batch_feat.append(id_feat[id])\n",
        "                    text_feat = get_input_data(id_text[id])\n",
        "                    batch_text.append(text_feat[0])\n",
        "                    batch_text2.append(text_feat[1])\n",
        "                except:\n",
        "                    print(id,str(traceback.format_exc()))\n",
        "\n",
        "            batch_images = torch.FloatTensor(batch_images).to('cuda')\n",
        "            batch_feat = torch.FloatTensor(batch_feat).to('cuda')\n",
        "            batch_text = torch.stack(batch_text, 0).to('cuda')\n",
        "            batch_text2 = torch.stack(batch_text2, 0).to('cuda')\n",
        "            output = model.forward2([batch_images.permute(0,3,1,2),batch_text,batch_text2,batch_feat])\n",
        "            temp = F.sigmoid(output).tolist()\n",
        "            for i,id in enumerate(batch_ids):\n",
        "                id_pred_mid[id] = temp[i]\n",
        "            output = output[:,0] - (output[:,1] + output[:,2]) * 0.5\n",
        "            valid_y2 = torch.FloatTensor(y).to('cuda')\n",
        "            output2 = F.sigmoid(output)\n",
        "            temp = F.sigmoid(output).view(-1).tolist()\n",
        "            for i,id in enumerate(batch_ids):\n",
        "                id_pred[id] = temp[i]\n",
        "\n",
        "        if MODE == \"VALID\":\n",
        "            pred_y = []\n",
        "            valid_y = []\n",
        "            for id in ids_list3:\n",
        "                pred_y.append(id_pred[id])\n",
        "                valid_y.append(id_label2[id])\n",
        "            print(sklearn.metrics.roc_auc_score(valid_y,pred_y),\n",
        "                  sklearn.metrics.accuracy_score(valid_y,np.array(pred_y)>0.5),\n",
        "                  sklearn.metrics.log_loss(valid_y,np.array(pred_y)))\n",
        "        \n",
        "        \n",
        "\n",
        "    if not ISPREDICT:\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/hateful-memes/weight' + '/model3_' + str(fold) + '.pt')\n",
        "    id_pred_mid_all.append(id_pred_mid)   \n",
        "    id_pred_all.append(id_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0c096dc6f1a468aa3850648f98b3ffb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ep 0\n",
            "loss: 0.029902664507136627\n",
            "ep 1\n",
            "loss: 0.026015563929782194\n",
            "ep 2\n",
            "loss: 0.02368540480732918\n",
            "ep 3\n",
            "loss: 0.02192556753579308\n",
            "ep 4\n",
            "loss: 0.019354386713574916\n",
            "ep 0\n",
            "loss: 0.030824500357403476\n",
            "ep 1\n",
            "loss: 0.026229807934340307\n",
            "ep 2\n",
            "loss: 0.024043077751117595\n",
            "ep 3\n",
            "loss: 0.021740008629420226\n",
            "ep 4\n",
            "loss: 0.019668048553607043\n",
            "ep 0\n",
            "loss: 0.030553939963088316\n",
            "ep 1\n",
            "loss: 0.026381476270801882\n",
            "ep 2\n",
            "loss: 0.02435575620917713\n",
            "ep 3\n",
            "loss: 0.022050655237015555\n",
            "ep 4\n",
            "loss: 0.019787018749643774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyxtIIVz_ZZL",
        "outputId": "0691b36d-6df8-47ec-ae4e-575018290d0e"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion2 = nn.BCEWithLogitsLoss(reduction = 'none')\n",
        "\n",
        "batch_size = 16\n",
        "pair_batch_size = 4\n",
        "valid_batch_num = 16\n",
        "n_batches = len(ids_list)//batch_size + 1\n",
        "valid_batch_num = len(ids_list3)//batch_size + 1\n",
        "valid_pair_batch_num = len(id_pair)//pair_batch_size + 1\n",
        "\n",
        "\n",
        "id_pred2_all = []\n",
        "for fold in range(3):\n",
        "    model = DensNet()\n",
        "    model.to('cuda')\n",
        "    optimizer2 = torch.optim.AdamW(model.parameters(), lr=1.5e-5, betas=(0.9, 0.999))\n",
        "    if ISPREDICT:\n",
        "        model.load_state_dict(torch.load(weight_path + '/model_3_' + str(fold) + '.pt'))\n",
        "    else:\n",
        "        for ep in range(6):\n",
        "            print('ep',ep)\n",
        "            random.shuffle(img_pairs)\n",
        "            random.shuffle(text_pairs)\n",
        "            model.train()\n",
        "            tloss2 = 0.0\n",
        "            tloss3 = 0.0\n",
        "            for b in range(n_batches):\n",
        "                pairs_backward = False\n",
        "                for pairs in [img_pairs,text_pairs]:\n",
        "                    start = b*pair_batch_size\n",
        "                    end = (b+1)*pair_batch_size\n",
        "                    if start >= len(pairs):\n",
        "                        continue\n",
        "                    batch_ids = pairs[start:end]\n",
        "                    batch_images_x1 = []\n",
        "                    batch_images_x2 = []\n",
        "                    batch_text_x = []\n",
        "                    batch_text2_x = []\n",
        "                    batch_text_x2 = []\n",
        "                    batch_text2_x2 = []\n",
        "                    batch_feat_x1 = []\n",
        "                    batch_feat_x2 = []\n",
        "                    y = []\n",
        "                    for i,id in enumerate(batch_ids):\n",
        "                        if len(batch_ids) == 0:\n",
        "                            continue\n",
        "                        try:\n",
        "                            if random.random() > 0.5:\n",
        "                                id1 = id[0]\n",
        "                                id2 = id[1]\n",
        "                            else:\n",
        "                                id1 = id[1]\n",
        "                                id2 = id[0]\n",
        "                            batch_images_x1.append(pic_cache[id1])\n",
        "                            batch_images_x2.append(pic_cache[id2])\n",
        "                            batch_feat_x1.append(id_feat[id1])\n",
        "                            batch_feat_x2.append(id_feat[id2])\n",
        "                            text_feat = get_input_data(id_text[id1])\n",
        "                            batch_text_x.append(text_feat[0])\n",
        "                            batch_text2_x.append(text_feat[1])\n",
        "                            text_feat = get_input_data(id_text[id2])\n",
        "                            batch_text_x2.append(text_feat[0])\n",
        "                            batch_text2_x2.append(text_feat[1])                    \n",
        "                            y.append([id_label.get(id1,-1),id_label.get(id2,-1)])\n",
        "\n",
        "                        except:\n",
        "                            print(id,str(traceback.format_exc()))\n",
        "                    y = torch.FloatTensor(y).to('cuda')\n",
        "                    batch_images_x1 = torch.FloatTensor(batch_images_x1).to('cuda')\n",
        "                    batch_images_x2 = torch.FloatTensor(batch_images_x2).to('cuda')\n",
        "                    batch_feat_x1 = torch.FloatTensor(batch_feat_x1).to('cuda')\n",
        "                    batch_feat_x2 = torch.FloatTensor(batch_feat_x2).to('cuda')\n",
        "                    batch_text_x = torch.stack(batch_text_x, 0).to('cuda')\n",
        "                    batch_text2_x = torch.stack(batch_text2_x, 0).to('cuda')\n",
        "                    batch_text_x2 = torch.stack(batch_text_x2, 0).to('cuda')\n",
        "                    batch_text2_x2 = torch.stack(batch_text2_x2, 0).to('cuda')\n",
        "                    output = model.pair_forward(x1 = [batch_images_x1.permute(0,3,1,2),batch_text_x,batch_text2_x,batch_feat_x1],\n",
        "                                        x2 = [batch_images_x2.permute(0,3,1,2),batch_text_x2,batch_text2_x2,batch_feat_x2])\n",
        "                    output2 = F.sigmoid(output)\n",
        "                    loss = criterion2(output.view(-1), y.view(-1))\n",
        "                    loss = loss * (1 - (y.view(-1) == -1).float()) * 0.3\n",
        "                    loss2 = F.relu(0.3 - (output2[:,0] - output2[:,1]) * \n",
        "                                   (y[:,0] - y[:,1])) * abs(y[:,0] - y[:,1]) * (1 - (y[:,0] == -1).float()) * (1 - (y[:,1] == -1).float())\n",
        "                    loss3 = loss.mean() + loss2.mean()\n",
        "                    loss3.backward()\n",
        "                    pairs_backward = True\n",
        "                    tloss2 += loss.mean().item()\n",
        "                    tloss3 += loss2.mean().item()\n",
        "                if b % 3 == 0 and pairs_backward:\n",
        "                    optimizer2.step()\n",
        "                    optimizer2.zero_grad()\n",
        "\n",
        "            print(\"loss:\",tloss2/len(ids_list),tloss3/len(ids_list))\n",
        "    if True:\n",
        "        model.eval()\n",
        "\n",
        "        id_pred2 = {}\n",
        "        for b in range(valid_pair_batch_num):\n",
        "            start = b*pair_batch_size\n",
        "            end = (b+1)*pair_batch_size\n",
        "            if start >= len(id_pair):\n",
        "                continue\n",
        "            batch_ids = id_pair[start:end]\n",
        "            batch_images_x1 = []\n",
        "            batch_images_x2 = []\n",
        "            batch_text_x = []\n",
        "            batch_text2_x = []\n",
        "            batch_text_x2 = []\n",
        "            batch_text2_x2 = []\n",
        "            batch_feat_x1 = []\n",
        "            batch_feat_x2 = []\n",
        "            y = []\n",
        "            for i,id in enumerate(batch_ids):\n",
        "                if len(batch_ids) == 0:\n",
        "                    continue\n",
        "                try:\n",
        "                    id1 = id[0]\n",
        "                    id2 = id[1]\n",
        "                    batch_images_x1.append(pic_cache[id1])\n",
        "                    batch_images_x2.append(pic_cache[id2])\n",
        "                    batch_feat_x1.append(id_feat[id1])\n",
        "                    batch_feat_x2.append(id_feat[id2])\n",
        "                    text_feat = get_input_data(id_text[id1])\n",
        "                    batch_text_x.append(text_feat[0])\n",
        "                    batch_text2_x.append(text_feat[1])\n",
        "                    text_feat = get_input_data(id_text[id2])\n",
        "                    batch_text_x2.append(text_feat[0])\n",
        "                    batch_text2_x2.append(text_feat[1])                    \n",
        "                    y.append([id_label2.get(id1,-1),id_label2.get(id2,-1)])\n",
        "\n",
        "                except:\n",
        "                    print(id,str(traceback.format_exc()))\n",
        "            y = torch.FloatTensor(y).to('cuda')\n",
        "            batch_images_x1 = torch.FloatTensor(batch_images_x1).to('cuda')\n",
        "            batch_images_x2 = torch.FloatTensor(batch_images_x2).to('cuda')\n",
        "            batch_feat_x1 = torch.FloatTensor(batch_feat_x1).to('cuda')\n",
        "            batch_feat_x2 = torch.FloatTensor(batch_feat_x2).to('cuda')\n",
        "            batch_text_x = torch.stack(batch_text_x, 0).to('cuda')\n",
        "            batch_text2_x = torch.stack(batch_text2_x, 0).to('cuda')\n",
        "            batch_text_x2 = torch.stack(batch_text_x2, 0).to('cuda')\n",
        "            batch_text2_x2 = torch.stack(batch_text2_x2, 0).to('cuda')\n",
        "            output = model.pair_forward(x1 = [batch_images_x1.permute(0,3,1,2),batch_text_x,batch_text2_x,batch_feat_x1],\n",
        "                                    x2 = [batch_images_x2.permute(0,3,1,2),batch_text_x2,batch_text2_x2,batch_feat_x2])\n",
        "            output2 = F.sigmoid(output)\n",
        "            temp = F.sigmoid(output).tolist()\n",
        "            for i,id in enumerate(batch_ids):\n",
        "                id1 = id[0]\n",
        "                id2 = id[1]\n",
        "                id_pred2[id1] = id_pred2.get(id1,[])\n",
        "                id_pred2[id2] = id_pred2.get(id2,[])\n",
        "                id_pred2[id1].append(temp[i][0])\n",
        "                id_pred2[id2].append(temp[i][1])\n",
        "                \n",
        "        if MODE == \"VALID\":\n",
        "            valid_y2 = []    \n",
        "            pred_y2 = []\n",
        "            for id,prob in id_pred2.items():\n",
        "                if id_label2.get(id,-1) == -1:\n",
        "                    continue\n",
        "                pred_y2.append(sum(id_pred2[id])/len(id_pred2[id]))\n",
        "                valid_y2.append(id_label2[id])\n",
        "            print(sklearn.metrics.roc_auc_score(valid_y2,pred_y2), \n",
        "                  sklearn.metrics.accuracy_score(valid_y2,np.array(pred_y2)>0.5),\n",
        "                  sklearn.metrics.log_loss(valid_y2,np.array(pred_y2)))\n",
        "        \n",
        "    if not ISPREDICT:\n",
        "        torch.save(model.state_dict(), weight_path + '/model_3_' + str(fold) + '.pt')\n",
        "    id_pred2_all.append(id_pred2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ep 0\n",
            "loss: 0.023026291070615545 0.013847773872315883\n",
            "ep 1\n",
            "loss: 0.01948554887534941 0.010246736875351738\n",
            "ep 2\n",
            "loss: 0.017268523512955974 0.007490061296259656\n",
            "ep 3\n",
            "loss: 0.016006245271686245 0.0061916649302139\n",
            "ep 4\n",
            "loss: 0.01447704778776011 0.005255515435600982\n",
            "ep 5\n",
            "loss: 0.01259418979980161 0.004075562885140671\n",
            "ep 0\n",
            "loss: 0.024032519914648113 0.014354261008255622\n",
            "ep 1\n",
            "loss: 0.021045294854570837 0.011416706752689446\n",
            "ep 2\n",
            "loss: 0.018936138981405427 0.008809712257455377\n",
            "ep 3\n",
            "loss: 0.017224477018722716 0.007128010899266776\n",
            "ep 4\n",
            "loss: 0.015475146891439662 0.006099139595732969\n",
            "ep 5\n",
            "loss: 0.013705593563944978 0.004681796408751431\n",
            "ep 0\n",
            "loss: 0.024119824036079294 0.014211416918565246\n",
            "ep 1\n",
            "loss: 0.019755513980546417 0.010439530624624561\n",
            "ep 2\n",
            "loss: 0.01759326904332813 0.008406572709188742\n",
            "ep 3\n",
            "loss: 0.01635115280977505 0.00716692290455103\n",
            "ep 4\n",
            "loss: 0.014708810888778637 0.006293723897022359\n",
            "ep 5\n",
            "loss: 0.013695594950524323 0.005321634588872685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pQduy6Xgwgx"
      },
      "source": [
        "id_pred_2 = {}\n",
        "for id in ids_list3:\n",
        "    id_pred_2[id] = (id_pred_all[0][id] +  id_pred_all[1][id] + id_pred_all[2][id])/3\n",
        "            \n",
        "id_pred2_2 = {}\n",
        "for id,prob in id_pred2_all[0].items():\n",
        "    if id_label2.get(id,-1) == -1:\n",
        "        continue\n",
        "    id_pred2_2[id] = np.mean([np.mean(id_pred2_all[0][id]),np.mean(id_pred2_all[1][id]),np.mean(id_pred2_all[2][id])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H_I9tSvicYD",
        "outputId": "725326dc-b5ea-4372-d39a-c7e25091ea0d"
      },
      "source": [
        "id_pred2_1_np = [[],[],[],[]]\n",
        "for id,prob in id_pred_all[0].items():\n",
        "    id_pred2_1_np[0].append(id_pred_all[0][id])\n",
        "    id_pred2_1_np[1].append(id_pred_all[1][id])\n",
        "    id_pred2_1_np[2].append(id_pred_all[2][id])\n",
        "    id_pred2_1_np[3].append(id_mmf.get(id,0))\n",
        "print(np.corrcoef(np.stack(id_pred2_1_np)))\n",
        "\n",
        "id_pred2_2_np = [[],[],[],[]]\n",
        "for id,prob in id_pred2_all[0].items():\n",
        "    if id_label2.get(id,-1) == -1:\n",
        "        continue\n",
        "    id_pred2_2_np[0].append(np.mean(id_pred2_all[0][id]))\n",
        "    id_pred2_2_np[1].append(np.mean(id_pred2_all[1][id]))\n",
        "    id_pred2_2_np[2].append(np.mean(id_pred2_all[2][id]))\n",
        "    id_pred2_2_np[3].append(id_mmf.get(id,0))\n",
        "print(np.corrcoef(np.stack(id_pred2_2_np)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.78876535 0.78109615 0.3511773 ]\n",
            " [0.78876535 1.         0.80410054 0.37660937]\n",
            " [0.78109615 0.80410054 1.         0.31509268]\n",
            " [0.3511773  0.37660937 0.31509268 1.        ]]\n",
            "[[1.         0.70394878 0.68523294 0.29035311]\n",
            " [0.70394878 1.         0.70446598 0.34953335]\n",
            " [0.68523294 0.70446598 1.         0.32496955]\n",
            " [0.29035311 0.34953335 0.32496955 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c61JxmMcjfjw"
      },
      "source": [
        "import pickle\n",
        "f = open(\"/content/drive/MyDrive/hateful-memes/weight/submission_3.pkl\", 'wb')\n",
        "pickle.dump([id_pred_2,id_pred2_2,id_mmf], f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}